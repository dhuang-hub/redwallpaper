{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from threading import Thread\n",
    "from praw import Reddit\n",
    "from praw.models.reddit.submission import Submission\n",
    "from redwallpaper import utils\n",
    "\n",
    "\n",
    "class RedWallpaperScraper:\n",
    "    \"\"\"\n",
    "    Initializes and creates an instance of scraped submissions to the /r/subreddit.\n",
    "    Stores submissions in the instance's 'wallpapers' attribute.\n",
    "    \"\"\"\n",
    "    \n",
    "    reddit_oath = {\n",
    "        'client_id': 'pIxpnAoiGfwE-g',\n",
    "        'client_secret': 'Ueccpv4dJegXUYbmAIdwxevxjDs',\n",
    "        'user_agent': 'wallpapers'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    imgur_oath = {\n",
    "        'client_id': '29b27fc1363aa92',\n",
    "        'client_secret': 'ef58b651b764dfb487809e64a2d62982e1a6392e'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    imgur_headers = {\n",
    "      'Authorization': f'Client-ID {imgur_oath[\"client_id\"]}'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_imgur(url):\n",
    "        \"\"\"\n",
    "        Queries the Imgur API with GET requests for images, given a valid Imgur url.\n",
    "        This method is called to extract image urls from albums/galleries of images.\n",
    "        \"\"\"\n",
    "        img_urls = []\n",
    "        imgur_hash = url.strip('/').split('/')[-1].split('?')[0]\n",
    "        \n",
    "        # Unpredictable API endpoint\n",
    "        api_album = f'https://api.imgur.com/3/album/{imgur_hash}/images'\n",
    "        api_gallery = f'https://api.imgur.com/3/gallery/album/{imgur_hash}'\n",
    "        api_kwargs = {\n",
    "            'method':'GET',\n",
    "            'url': None,\n",
    "            'headers': RedWallpaperScraper.imgur_headers,\n",
    "            'allow_redirects': False\n",
    "        }\n",
    "        \n",
    "        for endpoint in [api_album, api_gallery]:\n",
    "            api_kwargs['url'] = endpoint\n",
    "            response = requests.request(**api_kwargs)\n",
    "            if response.ok:\n",
    "                # Imgur is very unpredictable!\n",
    "                try:\n",
    "                    img_urls += [image['link'] for image in json.loads(response.text)['data']]\n",
    "                except TypeError:\n",
    "                    img_urls += [image['link'] for image in json.loads(response.text)['data']['images']]\n",
    "                break       \n",
    "        return img_urls\n",
    "    \n",
    "    \n",
    "    def __init__(self, sort='top', time_filter='week', limit=300):\n",
    "        \"\"\"\n",
    "        Initialize a wallpaper subreddit scraper instance with feed options.\n",
    "        Stores wallpaper urls in a 'wallpaper' instance attribute'.\n",
    "        Threaded extraction of urls allows for immediate access of wallpaper attribute\n",
    "        while full extraction funs in the background.\n",
    "        \n",
    "        Sort options: 'top' (default), 'controversial', 'gilded', 'hot', 'new', 'rising'\n",
    "        Time filters: 'week' (default), 'all', 'day', 'hour', 'month', 'year'\n",
    "        Limit: Scrapes up to 1000 (max) submissions, 300 by default\n",
    "        \"\"\"\n",
    "        self.wallpapers = []\n",
    "        self.loaded = False\n",
    "        \n",
    "        with Reddit(**self.reddit_oath) as R:\n",
    "            r_wallpapers = R.subreddit('wallpapers')\n",
    "            \n",
    "            # sort_options = {'controversial', 'gilded', 'hot', 'new', 'rising', 'top'}\n",
    "            # time_filter = {'all', 'day', 'hour', 'month', 'week', 'year'}\n",
    "            \n",
    "            if sort in {'controversial', 'top'}:\n",
    "                r_wallpapers = getattr(r_wallpapers, sort)(limit=limit, time_filter=time_filter)\n",
    "            else:\n",
    "                r_wallpapers = getattr(r_wallpapers, sort)(limit=limit)\n",
    "\n",
    "            Thread(target=self._get_all_wallpaper_url, args=(r_wallpapers,)).start()\n",
    "                \n",
    "                \n",
    "    def __iter__(self):\n",
    "        return iter(self.wallpapers)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.wallpapers)\n",
    "    \n",
    "    \n",
    "    def __bool__(self):\n",
    "        return self.loaded\n",
    "\n",
    "    \n",
    "    def _get_wallpaper_url(self, r_submission):\n",
    "        \"\"\"\n",
    "        Extract wallpaper url's from reddit submissions/posts. Appends to the instance's\n",
    "        'wallpaper' attribute.\n",
    "        \"\"\"\n",
    "        if isinstance(r_submission, Submission):\n",
    "            if utils.is_img_ext(r_submission.url):\n",
    "                self.wallpapers.append((r_submission.url, r_submission.thumbnail))\n",
    "            elif 'imgur' in r_submission.url[:15]: # No need to search entire string\n",
    "                self.wallpapers.extend([(url, None) for url in self.get_imgur(r_submission.url)])\n",
    "    \n",
    "    \n",
    "    def _get_all_wallpaper_url(self, r_wallpapers):\n",
    "        \"\"\"\n",
    "        Runs a fully looped extraction of the r_wallpaper generator, calling helper function\n",
    "        self._get_wallpaper_url\n",
    "        \"\"\"\n",
    "        for r_submission in r_wallpapers:\n",
    "            self._get_wallpaper_url(r_submission)\n",
    "        self.loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = RWallpaperScraper('top', 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
