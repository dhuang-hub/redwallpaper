{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New notebook to keep dev clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import praw\n",
    "from praw import Reddit\n",
    "\n",
    "class WallpaperScraper:\n",
    "    reddit_oath = {\n",
    "        'client_id': 'pIxpnAoiGfwE-g',\n",
    "        'client_secret': 'Ueccpv4dJegXUYbmAIdwxevxjDs',\n",
    "        'user_agent': 'wallpapers'\n",
    "    }\n",
    "    \n",
    "    imgur_oath = {\n",
    "    'client_id': '29b27fc1363aa92',\n",
    "    'client_secret': 'ef58b651b764dfb487809e64a2d62982e1a6392e'\n",
    "    }\n",
    "    \n",
    "    imgur_headers = {\n",
    "      'Authorization': f'Client-ID {imgur_oath[\"client_id\"]}'\n",
    "    }\n",
    "    \n",
    "#     sort_options = {'controversial', 'gilded', 'hot', 'new', 'rising', 'top'}\n",
    "#     time_filter = {'all', 'day', 'hour', 'month', 'week', 'year'}\n",
    "    \n",
    "    def __init__(self, img_dir, sort='top', time_filter='week'):\n",
    "        \"\"\"\n",
    "        Initialize a wallpaper subreddit scraper instance with feed options.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._img_dir = img_dir\n",
    "        self._mk_img_dir()\n",
    "        \n",
    "        self._wallpapers = Reddit(**self.reddit_oath).subreddit('wallpapers')\n",
    "        if sort in {'controversial', 'top'}:\n",
    "            self._wallpapers = getattr(self._wallpapers, sort)(time_filter=time_filter)\n",
    "        else:\n",
    "            self._wallpapers = getattr(self._wallpapers, sort)()\n",
    "        \n",
    "    def _mk_img_dir(self):\n",
    "        \"\"\"\n",
    "        Checks and initializes a directory for image files to be downloaded.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self._img_dir):\n",
    "            os.mkdir(self._img_dir)\n",
    "        if not os.path.exists(os.path.join(self._img_dir, 'buffer')):\n",
    "            os.mkdir(os.path.join(self._img_dir, 'buffer'))\n",
    "            \n",
    "    def _img_url_extract(self, img_sub):\n",
    "        \"\"\"\n",
    "        Extract and return the url hyperlink of only PRAW's submission-type objects.\n",
    "        \"\"\"\n",
    "        if isinstance(img_sub, praw.models.reddit.submission.Submission):\n",
    "            return img_sub.url\n",
    "        return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test = Reddit(**WallpaperScraper.reddit_oath).subreddit('wallpapers')\n",
    "\n",
    "# Time filters only allowed for 'controversial' and 'top' sort orders\n",
    "\n",
    "for i in ['controversial', 'gilded', 'hot', 'new', 'rising', 'top']:\n",
    "    for j in ['all', 'day', 'hour', 'month', 'week', 'year']:\n",
    "        try:\n",
    "            getattr(test, i)(time_filter=j)\n",
    "        except:\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WallpaperScraper('wallpapers', 'controversial', 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://imgur.com/a/22D4xOJ com/a/22D4xOJ https://b.thumbs.redditmedia.com/SSWGbJdT06dgxC7DPRUBMy2FjzV_JfwovqVVISHdgjI.jpg\n",
      "https://i.redd.it/o1vmuo8vend21.jpg jpg https://b.thumbs.redditmedia.com/e8B7NrIZktnovKk-92O2KTZrXm9_TvSG8oJz3CgYjiI.jpg\n",
      "https://i.redd.it/urs703bti4f31.jpg jpg https://b.thumbs.redditmedia.com/gTMLYkASEJ-AUwROYXGDx2pjAWz1NcBJCftzDTpXtkU.jpg\n",
      "https://i.redd.it/w3j6kry5mvu21.jpg jpg https://a.thumbs.redditmedia.com/_nnn6idTvszlVdR9X9YT26zRkGsucCLSb-_jLCdbC74.jpg\n",
      "https://i.redd.it/dc3m37tcbdj31.jpg jpg https://b.thumbs.redditmedia.com/KEKE9kIJ9-qK-GduhhggVD1W9T1G5GFrKm6oF0pwprw.jpg\n",
      "https://i.redd.it/bmp9m1mrzyg31.jpg jpg https://b.thumbs.redditmedia.com/-lUkWa9M9BmewRGV2HzaG6-xBtzPWXjdwIGJnPIjWMs.jpg\n",
      "https://i.redd.it/5fcdmvjfzmy21.jpg jpg https://b.thumbs.redditmedia.com/Y_Zo2ch29bXxsKh1n8CGJORAytnHnYT32rbaGbWu8cg.jpg\n",
      "https://i.redd.it/75fvuwxirjy21.jpg jpg https://b.thumbs.redditmedia.com/KbcC0ccUjB77SMZ7A5Y-gh3BBG2Evolx8_dlwnrlsGM.jpg\n",
      "https://i.redd.it/hne6x6uo84h31.png png https://b.thumbs.redditmedia.com/9ssNa2MfEfIyxzpppxlgJvFHhvy_aZqKLXvgLcSsEjg.jpg\n",
      "https://i.imgur.com/rbpgj4T.jpg jpg https://a.thumbs.redditmedia.com/30LKyE-tWI0NXiQ5-hV8qmaRGdXtrZQvxfI4Hgdm8T0.jpg\n",
      "https://i.imgur.com/mqqeOPl.jpg jpg https://b.thumbs.redditmedia.com/JGaHwy6T6wTo3dQZ8c5v_Tv_og33kBE7rZpwpUo812g.jpg\n"
     ]
    }
   ],
   "source": [
    "for idx, img_sub in enumerate(test._wallpapers):\n",
    "    if isinstance(img_sub, praw.models.reddit.submission.Submission):\n",
    "        img_sub.url.split('.')[-1]\n",
    "        file_ext = img_sub.url.split('.')[-1]\n",
    "        print(img_sub.url, file_ext, img_sub.thumbnail)\n",
    "    #     with open(f'tmp/tmp{idx}.{file_ext}', 'wb') as tmp:\n",
    "    #         r = requests.get(img_sub.url, stream=True)\n",
    "    #         if r.ok:\n",
    "    #             tmp.write(r.content)\n",
    "    #     file_ext = img_sub.thumbnail.split('.')[-1]\n",
    "    #     with open(f'tmp/tmp{idx}_.{file_ext}', 'wb') as tmp:\n",
    "    #         r = requests.get(img_sub.thumbnail, stream=True)\n",
    "    #         if r.ok:\n",
    "    #             tmp.write(r.content)\n",
    "    \n",
    "    if idx == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to develop a class - image generator\n",
    "\n",
    "- Scrape only scrapable images\n",
    "    - Predictable scrapes: e.g. imgur/reddit\n",
    "        - Reddit API provides a thumbnail!! - Great for speed-up of image processing and IO\n",
    "    - Unpredictable scrapes: Other sites/reddit comments\n",
    "- Develop a pre-buffer\n",
    "    - Image pops are quick, but buffer can buffer in the background\n",
    "    - Store image in buffer folder\n",
    "    > 1 - URL Buffer\n",
    "    \n",
    "    > 2 - Image Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _img_url_extract(img_sub):\n",
    "    \"\"\"\n",
    "    Extract and return the url hyperlink of only PRAW's submission-type objects.\n",
    "    Include the link to a thumbnail if it exists\n",
    "    \"\"\"\n",
    "    if isinstance(img_sub, praw.models.reddit.submission.Submission):\n",
    "        return (img_sub.url, img_sub.thumbnail)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _valid_url(url):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgur_gallery_generator(gallery_url):\n",
    "    assert gallery_url\n",
    "    \n",
    "# https://imgur.com/a/WepxW\n",
    "# https://imgur.com/a/rSZlZ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
